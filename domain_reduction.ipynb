{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Domain Reduction\n",
    "\n",
    "## Background\n",
    "Sequential domain reduction is a process where the bounds of the optimization problem are mutated (typically contracted) to reduce the time required to converge to an optimal value. The advantage of this method is typically seen when a cost function is particularly expensive to calculate, or if the optimization routine oscilates heavily. \n",
    "\n",
    "## Basics\n",
    "\n",
    "The basic steps are a *pan* and a *zoom*. These two steps are applied at one time, therefore updating the problem search space evey iteration.\n",
    "\n",
    "**Pan**: recentering the region of interest around the most optimal point found.\n",
    "\n",
    "**Zoom**: contract the region of interest.\n",
    "\n",
    "![](sdr.png)\n",
    "\n",
    "\n",
    "## Parameters\n",
    "\n",
    "There are three parameters for the built-in `SequentialDomainReductionTransformer` object:\n",
    "\n",
    "\n",
    "$\\gamma_{osc}:$ shrinkage  parameter  for  oscillation. Typically [0.5-0.7]. Default = 0.7\n",
    "\n",
    "$\\gamma_{pan}:$ panning parameter. Typically 1.0. Default = 1.0\n",
    "\n",
    "$\\eta:$ zoom parameter. Default = 0.9\n",
    "\n",
    "\n",
    "More information can be found in this reference document:\n",
    "\n",
    "---\n",
    "\n",
    "Title: \"On the robustness of a simple domain reduction scheme for simulation‚Äêbased optimization\" \n",
    "\n",
    "Date: 2002 \n",
    "\n",
    "Author: Stander, N. and Craig, K. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "Let's start by importing the packages we'll be needing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bayes_opt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-27db379beef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequentialDomainReductionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bayes_opt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import SequentialDomainReductionTransformer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an example cost function. This is the [Ackley function](https://en.wikipedia.org/wiki/Ackley_function), which is quite non-linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ackley(**kwargs):\n",
    "    x = np.fromiter(kwargs.values(), dtype=float)\n",
    "    arg1 = -0.2 * np.sqrt(0.5 * (x[0] ** 2 + x[1] ** 2))\n",
    "    arg2 = 0.5 * (np.cos(2. * np.pi * x[0]) + np.cos(2. * np.pi * x[1]))\n",
    "    return -1.0 * (-20. * np.exp(arg1) - np.exp(arg2) + 20. + np.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the standard bounds for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pbounds = {'x': (-5, 5), 'y': (-5, 5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "This is where we define our `bound_transformer` , the Sequential Domain Reduction Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_transformer = SequentialDomainReductionTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up two idential optimization problems, except one has the `bound_transformer` variable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutating_optimizer = BayesianOptimization(\n",
    "    f=ackley,\n",
    "    pbounds=pbounds,\n",
    "    verbose=0,\n",
    "    random_state=1,\n",
    "    bounds_transformer=bounds_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutating_optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_optimizer = BayesianOptimization(\n",
    "    f=ackley,\n",
    "    pbounds=pbounds,\n",
    "    verbose=0,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After both have completed we can plot to see how the objectives performed. It's quite obvious to see that the Sequential Domain Reduction technique contracted onto the optimal point relativly quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mutating_optimizer.space.target, label='Mutated Optimizer')\n",
    "plt.plot(standard_optimizer.space.target, label='Standard Optimizer')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the actual contraction of one of the variables (`x`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example x-bound shrinking\n",
    "x_min_bound = [b[0][0] for b in bounds_transformer.bounds]\n",
    "x_max_bound = [b[0][1] for b in bounds_transformer.bounds]\n",
    "x = [x[0] for x in mutating_optimizer.space.params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_min_bound[1:], label='x lower bound')\n",
    "plt.plot(x_max_bound[1:], label='x upper bound')\n",
    "plt.plot(x[1:], label='x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
